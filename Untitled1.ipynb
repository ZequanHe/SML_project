{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f714afb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from typing import *\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57c92799",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train.json\",\"r\") as fin:\n",
    "    train_data = json.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3130923",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test.json\",\"r\") as fin:\n",
    "    test_data = json.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f98ba73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take out prolific author and coauthor\n",
    "for data in train_data:\n",
    "    data[\"coauthors\"] = [author for author in data[\"authors\"] if author not in range(100)]\n",
    "    data[\"prolific_author\"] = [author for author in data[\"authors\"] if author in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c643ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'authors': [42, 13720, 36], 'year': 9, 'abstract': [2455, 1858, 2335, 1543, 1800, 1860, 2000, 2867, 1546, 1874, 2059, 1525, 2590, 4196, 12, 2634, 1543, 1800, 1586, 2866, 3595, 1866, 1670, 2000, 3743, 1542, 1650, 1527, 33, 4407, 1543, 1535, 1962, 1961, 1543, 33, 1700, 1543, 1535, 1647, 1546, 1580, 4720, 12, 1731, 4231, 2601, 1553, 1704, 1605, 2456, 1543, 3281, 1594, 4407, 2168, 1542, 1586, 3781, 2471, 1525, 1859, 1669, 2512, 4572, 1546, 1609, 3781, 2471, 1525, 3393, 12, 37, 1712, 1586, 4196, 1650, 1527, 3281, 1594, 4407, 1800, 4708, 1904, 2059, 2411, 12], 'venue': 20, 'title': [41, 1550, 1563, 1594, 1544, 1919, 1644, 37, 1539, 1715, 1553, 1541, 1536, 1532, 1872, 1538], 'coauthors': [13720], 'prolific_author': [42, 36]}\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1aa5f4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using one-hot method \n",
    "venues_num = 466\n",
    "coauthors_num =21246\n",
    "polific_author_num = 100\n",
    "year_num = 20\n",
    "words_num = 4999\n",
    "def one_hot_vector(instance:Dict):\n",
    "    \n",
    "    venue_hot=np.zeros(venues_num)\n",
    "    venue = instance[\"venue\"]\n",
    "    if venue == \"\":\n",
    "        venue = venues_num-1\n",
    "    venue_hot[venue] = 1\n",
    "    \n",
    "    year_hot=np.zeros(year_num)\n",
    "    years = instance[\"year\"]\n",
    "    year_hot[years] =1\n",
    "    \n",
    "    coau_hot=np.zeros(coauthors_num)\n",
    "    coau = instance[\"coauthors\"]\n",
    "    coau_hot[coau] =1\n",
    "    \n",
    "    title_hot=np.zeros(words_num)\n",
    "    for title in instance[\"title\"]:\n",
    "        title_hot[title-1] =1\n",
    "        \n",
    "    abstr_hot=np.zeros(words_num)\n",
    "    for abstr in instance[\"abstract\"]:\n",
    "        abstr_hot[abstr-1] =1\n",
    "        \n",
    "    return np.concatenate([venue_hot,year_hot,coau_hot,title_hot,abstr_hot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f8c0038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi_label binary vector\n",
    "def binary_vector(instance):\n",
    "    target_bin = np.zeros(polific_author_num)\n",
    "    for pro_au in instance[\"prolific_author\"]:\n",
    "        target_bin[pro_au] =1\n",
    "    return target_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f5a6176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42, 36]\n"
     ]
    }
   ],
   "source": [
    "binary_vector(train_data[0])\n",
    "#print(train_data[0][\"prolific_author\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a6ccb30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the dataset \n",
    "def dataset_cr(dataset,is_test = False):\n",
    "    train_xs = []\n",
    "    train_ys = []\n",
    "    for instance in dataset:\n",
    "        train_xs.append(one_hot_vector(instance))\n",
    "        if is_test == False:\n",
    "            \n",
    "            train_ys.append(binary_vector(instance))\n",
    "    return np.vstack(train_xs),np.array(train_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2fa724cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_cr(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3dc05f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25793, 31730), (25793, 100))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x,train_y = dataset_cr(train_data)\n",
    "train_x.shape,train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5eb91669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary classification , 1 or 0\n",
    "#multi-class classification label , {0,1,2,3,4,5,6} ->[4]\n",
    "#multi-label classification label ,{0,1,2,3,4,5,6} ->[0,1,5]\n",
    "# this project is multi-label classification label\n",
    "#train_x = (n_sample,m_feature)\n",
    "x_train,x_dev,y_train,y_dev = train_test_split(train_x,train_y,test_size = 0.3,random_state = 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4741aafb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20634, 31730), (5159, 31730), (20634, 100), (5159, 100))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_x = (n_sample,m_feature)\n",
    "x_train.shape,x_dev.shape,y_train.shape,y_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fce3bfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#classical statistical model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eb4606af",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_samp = x_train[:30]\n",
    "y_train_samp = y_train[:30]\n",
    "x_dev_samp = x_dev[:5]\n",
    "y_dev_samp = y_dev[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1f10d72c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/8d/90hwsndn5txczrfyt4chjkp80000gn/T/ipykernel_19986/111747735.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmultino\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclssifi\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mOneVsRestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmultino\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclssifi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/CV1/lib/python3.7/site-packages/sklearn/multiclass.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    345\u001b[0m                 ],\n\u001b[1;32m    346\u001b[0m             )\n\u001b[0;32m--> 347\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m         )\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/CV1/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/CV1/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/CV1/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/CV1/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/CV1/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "multino = MultinomialNB(alpha=0.01)\n",
    "clssifi= OneVsRestClassifier(estimator=multino, n_jobs =4)\n",
    "clssifi.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004782f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "dev_predi = clssifi.predict(x_dev)\n",
    "dev_score = f1_score(dev_predi,y_dev,average='samples')\n",
    "print(dev_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17341b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing \n",
    "test_x,test_y = dataset_cr(test_data,is_test = True)\n",
    "test_pred = clssifi.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4923e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "answer=dict()\n",
    "head = [\"ID\",'Predict']\n",
    "with open(\"solution.csv\",\"w\") as csvfile:\n",
    "    writer = csv.DictWriter(csvfile,fieldnames = head)\n",
    "    writer.writeheader()\n",
    "    for idx,row in enumerate(test_pred):\n",
    "        result = [str(each) for each in np.where(row ==1)[0].tolist()]\n",
    "        predict =-1 if len(result) == else \" \".join(result)\n",
    "        writer.writerow({\"ID\":idx,\"Predict\":predict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d5c10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network based\n",
    "#embedding method\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fa4c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using torch method \n",
    "venues_num = 466\n",
    "coauthors_num =21246\n",
    "polific_author_num = 100\n",
    "year_num = 20\n",
    "words_num = 4999\n",
    "def torch_vector(instance:Dict):\n",
    "    \n",
    "    return {\"venue\":instance[\"venue\"],\n",
    "            \"year\":instance[\"year\"],\n",
    "            \"coauthor\":instance[\"coauthor\"],\n",
    "            \"title\":instance[\"title\"],\n",
    "            \"abstract\",instance[\"abstract\"],}\n",
    "        \n",
    "    #return np.concatenate([venue_hot,year_hot,coau_hot,title_hot,abstr_hot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e4113f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi_label torch vector\n",
    "def torch_vector(instance):\n",
    "    target_bin = np.zeros(polific_author_num)\n",
    "    for pro_au in instance[\"prolific_author\"]:\n",
    "        target_bin[pro_au] =1\n",
    "    return target_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1856c150",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the dataset \n",
    "def dataset_cr_torch(dataset,is_test = False):\n",
    "    train_xs = []\n",
    "    train_ys = []\n",
    "    for instance in dataset:\n",
    "        train_xs.append(torch_vector(instance))\n",
    "        if is_test == False:\n",
    "            train_ys.append(torch_vector(instance))\n",
    "    return np.vstack(train_xs),np.array(train_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d29217",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ner,y_ner = dataset_cr_torch(train_data)\n",
    "x_ner.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1ebda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a data type for author \n",
    "class authordataset(Dataset):\n",
    "    #input raw data\n",
    "    def __init__(self,data_raw):\n",
    "        self.train_xs,self.train_ys = dataset_cr_torch(data_raw)\n",
    "    def __len__(self):\n",
    "        return len(self.train_ys)\n",
    "    def __getitem__(self,idx):\n",
    "        return self.train_xs[idx], self.train_ys[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c653bcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_t = authordataset(train_data[:50])\n",
    "dev_set_t = authordataset(train_data[51:100])\n",
    "print(len(train_set_t))\n",
    "print(len(dev_set_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb84ec3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def colfunction(records):\n",
    "    \"\"\"\n",
    "    record-> list ,include 2-tuple\n",
    "    \"\"\"\n",
    "    \n",
    "    coauthors = []\n",
    "    venues =[]\n",
    "    title = []\n",
    "    abstract = []\n",
    "    year = []\n",
    "    y_train=[]\n",
    "    for data,label in records:\n",
    "        coauthors.append(torch.LongTensor(data['coauthors']))\n",
    "        venues.append(data['venue'])\n",
    "        year.append(data['year'])\n",
    "        title.append(torch.LongTensor(data['title']))\n",
    "        abstract.append(torch.LongTensor(data['abstract']))\n",
    "        y_train.append(label)\n",
    "    return {\n",
    "        'coauthors':coauthors, 'venues': torch.LongTensor(venues),\n",
    "        'years':torch.LongTensor(year),'title':title,\n",
    "        'abstract':abstract,\n",
    "        'labels':torch.FloatTensor(y_train)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7bc702",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using DataLoader to preprocess the data (iterator)\n",
    "train_data = DataLoader(train_set_t,batch_size = 8,shuffle=True,collate_fn =colfunction )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
