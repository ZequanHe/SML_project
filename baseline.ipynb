{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "e3a11320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "271e8f4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_json(\"train.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e65492b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25793, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0b4482e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>year</th>\n",
       "      <th>abstract</th>\n",
       "      <th>venue</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[42, 13720, 36]</td>\n",
       "      <td>9</td>\n",
       "      <td>[2455, 1858, 2335, 1543, 1800, 1860, 2000, 286...</td>\n",
       "      <td>20</td>\n",
       "      <td>[41, 1550, 1563, 1594, 1544, 1919, 1644, 37, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1359, 15881, 45]</td>\n",
       "      <td>15</td>\n",
       "      <td>[40, 1542, 1691, 2449, 1535, 3616, 2206, 1904,...</td>\n",
       "      <td>2</td>\n",
       "      <td>[1731, 47, 11, 57, 4624, 1525, 1535, 47, 11, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[19166, 17763]</td>\n",
       "      <td>17</td>\n",
       "      <td>[40, 1542, 1691, 2449, 1535, 2610, 1543, 1535,...</td>\n",
       "      <td></td>\n",
       "      <td>[2085, 1719, 1846, 1745, 2243, 1553, 1606, 159...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[97]</td>\n",
       "      <td>10</td>\n",
       "      <td>[46, 1624, 1547, 56, 1687, 1644, 6, 7, 3386, 1...</td>\n",
       "      <td>4</td>\n",
       "      <td>[40, 1733, 1735, 1540, 1655, 46, 1624, 1547, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[19617, 2]</td>\n",
       "      <td>10</td>\n",
       "      <td>[37, 3709, 3836, 1586, 2151, 1727, 3021, 1860,...</td>\n",
       "      <td>9</td>\n",
       "      <td>[38, 1592, 2088, 1543, 1574, 1727, 1597, 1813,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             authors  year                                           abstract  \\\n",
       "0    [42, 13720, 36]     9  [2455, 1858, 2335, 1543, 1800, 1860, 2000, 286...   \n",
       "1  [1359, 15881, 45]    15  [40, 1542, 1691, 2449, 1535, 3616, 2206, 1904,...   \n",
       "2     [19166, 17763]    17  [40, 1542, 1691, 2449, 1535, 2610, 1543, 1535,...   \n",
       "3               [97]    10  [46, 1624, 1547, 56, 1687, 1644, 6, 7, 3386, 1...   \n",
       "4         [19617, 2]    10  [37, 3709, 3836, 1586, 2151, 1727, 3021, 1860,...   \n",
       "\n",
       "  venue                                              title  \n",
       "0    20  [41, 1550, 1563, 1594, 1544, 1919, 1644, 37, 1...  \n",
       "1     2  [1731, 47, 11, 57, 4624, 1525, 1535, 47, 11, 3...  \n",
       "2        [2085, 1719, 1846, 1745, 2243, 1553, 1606, 159...  \n",
       "3     4  [40, 1733, 1735, 1540, 1655, 46, 1624, 1547, 5...  \n",
       "4     9  [38, 1592, 2088, 1543, 1574, 1727, 1597, 1813,...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "14cb36a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prolific_authors(authors):\n",
    "    \"\"\"Filter a list of authors to contain prolific authors only (ID < 100)\n",
    "\n",
    "    Parameters\n",
    "    ----------        \n",
    "    authors : \n",
    "        A list of authors. \n",
    "\n",
    "    -------\n",
    "    Return \n",
    "    y : \n",
    "        A list of prolific authors.\n",
    "    \n",
    "    \"\"\"\n",
    "    return list(filter(lambda x: x < 100, authors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "57a86b32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[42, 36], [45], [], [97], [2]]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = list(map(get_prolific_authors, train_data[\"authors\"].tolist()))\n",
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e0bfea7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [2455, 1858, 2335, 1543, 1800, 1860, 2000, 286...\n",
       "1    [40, 1542, 1691, 2449, 1535, 3616, 2206, 1904,...\n",
       "2    [40, 1542, 1691, 2449, 1535, 2610, 1543, 1535,...\n",
       "3    [46, 1624, 1547, 56, 1687, 1644, 6, 7, 3386, 1...\n",
       "4    [37, 3709, 3836, 1586, 2151, 1727, 3021, 1860,...\n",
       "Name: abstract, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_data[\"abstract\"]\n",
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "63d107c7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([87])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensor = [ torch.tensor(X, dtype=torch.float32) for X in X_train ]\n",
    "X_train_tensor[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "31f7dd10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train.values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f858f1",
   "metadata": {},
   "source": [
    "Prepare y output and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "46debb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def author_ids_to_multi_hot(authors):\n",
    "    \"\"\"Convert author id to multi-hot representation\n",
    "\n",
    "    Parameters\n",
    "    ----------        \n",
    "    authors : \n",
    "        A list of author ids (<100). e.g. [23, 47]\n",
    "\n",
    "    -------\n",
    "    Return \n",
    "    y : \n",
    "        A list of zeors and ones of length 100. [0, 0, 0, .... 1, 0, 0, 0, ... 1, 0, 0, .....]\n",
    "    \n",
    "    \"\"\"\n",
    "    tensor = torch.zeros(1, 100, dtype=torch.float32)\n",
    "    for i, author_id in enumerate(authors):\n",
    "        tensor[0][author_id] = 1  \n",
    "    return torch.squeeze(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "c08b06d2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_ids_to_multi_hot(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "187db84b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_hot_y_train = list(map(author_ids_to_multi_hot, y_train))\n",
    "multi_hot_y_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "902fd2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "d7597af4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0022)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guess = torch.zeros(1, 100, dtype=torch.float32)\n",
    "guess[0][1] = 0.8\n",
    "guess[0][2] = 1\n",
    "guess2 = torch.zeros(1, 100, dtype=torch.float32)\n",
    "guess2[0][1] = 1\n",
    "# truth = author_ids_to_multi_hot(y_train[0])\n",
    "criterion(input=guess, target=guess2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "c23b3085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5000, 0.6900, 0.7311, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
       "         0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
       "         0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
       "         0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
       "         0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
       "         0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
       "         0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
       "         0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
       "         0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
       "         0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
       "         0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
       "         0.5000]])"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.Sigmoid()\n",
    "m(guess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4442fa8",
   "metadata": {},
   "source": [
    "Load test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "286fb413",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_json(\"test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "a092546f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 6)"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "55d61269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>coauthors</th>\n",
       "      <th>year</th>\n",
       "      <th>abstract</th>\n",
       "      <th>venue</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[16336, 1762, 4357, 12564]</td>\n",
       "      <td>19</td>\n",
       "      <td>[37, 1662, 3207, 10, 33, 2037, 1738, 1642, 155...</td>\n",
       "      <td>223</td>\n",
       "      <td>[3207, 24, 1798, 1738, 37, 2375, 1568, 11, 53,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[21189, 14088]</td>\n",
       "      <td>19</td>\n",
       "      <td>[1731, 2130, 3674, 1705, 1656, 3077, 1546, 367...</td>\n",
       "      <td>223</td>\n",
       "      <td>[40, 1560, 1536, 1544, 1609, 1705, 1658, 1543,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[3625, 1198, 19889, 794, 2749, 7801]</td>\n",
       "      <td>19</td>\n",
       "      <td>[1551, 1728, 3920, 1542, 1535, 1656, 1543, 153...</td>\n",
       "      <td>7</td>\n",
       "      <td>[47, 1574, 1729, 1641, 11, 37, 2533, 2015, 47,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[19810, 15173, 5876, 111]</td>\n",
       "      <td>19</td>\n",
       "      <td>[51, 1535, 2115, 1543, 1811, 1700, 1657, 1684,...</td>\n",
       "      <td>21</td>\n",
       "      <td>[1770, 53, 2054, 1549, 1529, 1723, 2796, 1547,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[10932, 7668, 11907, 19601, 15307, 10492, 1049...</td>\n",
       "      <td>19</td>\n",
       "      <td>[1775, 1746, 1842, 1525, 33, 2551, 1882, 1542,...</td>\n",
       "      <td></td>\n",
       "      <td>[18, 1924, 23, 1544, 3927, 2686, 1543, 1535, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   identifier                                          coauthors  year  \\\n",
       "0           0                         [16336, 1762, 4357, 12564]    19   \n",
       "1           1                                     [21189, 14088]    19   \n",
       "2           2               [3625, 1198, 19889, 794, 2749, 7801]    19   \n",
       "3           3                          [19810, 15173, 5876, 111]    19   \n",
       "4           4  [10932, 7668, 11907, 19601, 15307, 10492, 1049...    19   \n",
       "\n",
       "                                            abstract venue  \\\n",
       "0  [37, 1662, 3207, 10, 33, 2037, 1738, 1642, 155...   223   \n",
       "1  [1731, 2130, 3674, 1705, 1656, 3077, 1546, 367...   223   \n",
       "2  [1551, 1728, 3920, 1542, 1535, 1656, 1543, 153...     7   \n",
       "3  [51, 1535, 2115, 1543, 1811, 1700, 1657, 1684,...    21   \n",
       "4  [1775, 1746, 1842, 1525, 33, 2551, 1882, 1542,...         \n",
       "\n",
       "                                               title  \n",
       "0  [3207, 24, 1798, 1738, 37, 2375, 1568, 11, 53,...  \n",
       "1  [40, 1560, 1536, 1544, 1609, 1705, 1658, 1543,...  \n",
       "2  [47, 1574, 1729, 1641, 11, 37, 2533, 2015, 47,...  \n",
       "3  [1770, 53, 2054, 1549, 1529, 1723, 2796, 1547,...  \n",
       "4  [18, 1924, 23, 1544, 3927, 2686, 1543, 1535, 1...  "
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "9fd1bdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_data[\"abstract\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "bad74bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tensor = [ torch.tensor(X, dtype=torch.float32) for X in X_test ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "c829553d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = test_data[\"identifier\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba47d79d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e76b05fc",
   "metadata": {},
   "source": [
    "Prepare data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "992a4f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = list(zip(X_train_tensor[:2000], multi_hot_y_train[:2000]))\n",
    "testset = list(zip(X_test_tensor, test_ids))\n",
    "# testset = list(zip(X_train_tensor[20000:21000], multi_hot_y_train[20000:21000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "359f05f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2455., 1858., 2335., 1543., 1800., 1860., 2000., 2867., 1546., 1874.,\n",
      "         2059., 1525., 2590., 4196.,   12., 2634., 1543., 1800., 1586., 2866.,\n",
      "         3595., 1866., 1670., 2000., 3743., 1542., 1650., 1527.,   33., 4407.,\n",
      "         1543., 1535., 1962., 1961., 1543.,   33., 1700., 1543., 1535., 1647.,\n",
      "         1546., 1580., 4720.,   12., 1731., 4231., 2601., 1553., 1704., 1605.,\n",
      "         2456., 1543., 3281., 1594., 4407., 2168., 1542., 1586., 3781., 2471.,\n",
      "         1525., 1859., 1669., 2512., 4572., 1546., 1609., 3781., 2471., 1525.,\n",
      "         3393.,   12.,   37., 1712., 1586., 4196., 1650., 1527., 3281., 1594.,\n",
      "         4407., 1800., 4708., 1904., 2059., 2411.,   12.]])\n",
      "author: tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "tensor([[4.0000e+01, 1.5420e+03, 1.6910e+03, 2.4490e+03, 1.5350e+03, 3.6160e+03,\n",
      "         2.2060e+03, 1.9040e+03, 1.6420e+03, 1.5430e+03, 1.5350e+03, 2.0070e+03,\n",
      "         1.6690e+03, 2.8690e+03, 1.5430e+03, 2.1740e+03, 2.6380e+03, 5.5000e+01,\n",
      "         2.0350e+03, 4.6280e+03, 6.0000e+00, 4.7000e+01, 1.1000e+01, 7.0000e+00,\n",
      "         1.5460e+03, 1.5350e+03, 4.7000e+01, 3.5220e+03, 2.2230e+03, 1.6560e+03,\n",
      "         1.2000e+01, 1.6060e+03, 5.7000e+01, 4.6240e+03, 2.1990e+03, 1.5400e+03,\n",
      "         2.2060e+03, 1.9770e+03, 1.9470e+03, 2.8860e+03, 1.5490e+03, 2.1520e+03,\n",
      "         1.1000e+01, 2.8860e+03, 1.9770e+03, 1.5490e+03, 2.4520e+03, 3.3000e+01,\n",
      "         3.7230e+03, 4.1720e+03, 1.5460e+03, 4.0820e+03, 3.9990e+03, 3.9800e+03,\n",
      "         1.5460e+03, 1.6240e+03, 1.5290e+03, 1.7190e+03, 1.1000e+01, 1.5460e+03,\n",
      "         1.7190e+03, 3.4910e+03, 2.2060e+03, 2.2120e+03, 1.5250e+03, 1.5350e+03,\n",
      "         1.5310e+03, 4.6000e+01, 1.5420e+03, 1.5580e+03, 2.1750e+03, 1.7450e+03,\n",
      "         2.2430e+03, 6.0000e+00, 7.0000e+00, 1.2000e+01, 1.6060e+03, 1.6420e+03,\n",
      "         1.5420e+03, 2.8300e+03, 1.5270e+03, 1.5350e+03, 4.7000e+01, 1.1000e+01,\n",
      "         3.5220e+03, 4.0000e+01, 1.9860e+03, 1.6530e+03, 4.7620e+03, 2.9910e+03,\n",
      "         1.5490e+03, 2.5250e+03, 1.5350e+03, 4.3450e+03, 1.2000e+01, 1.9000e+01,\n",
      "         1.5000e+01, 4.0000e+00, 1.5250e+03, 1.5000e+01, 1.1000e+01, 2.4200e+03,\n",
      "         1.5270e+03, 1.5350e+03, 4.7950e+03, 3.4000e+01, 2.1440e+03, 3.6000e+01,\n",
      "         2.1240e+03, 1.7770e+03, 1.2000e+01]])\n",
      "author: tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=1, shuffle=False, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False, drop_last=True)\n",
    "counter = 0\n",
    "for i, data in enumerate(train_loader):\n",
    "    if counter >= 2:\n",
    "        break\n",
    "    counter += 1\n",
    "    abstract, author = data\n",
    "    print(abstract[:5])\n",
    "    print(\"author:\", author)\n",
    "    print(criterion(input=author, target=author))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09567140",
   "metadata": {},
   "source": [
    "Baseline RNN (only use abstract as input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "2d3ae28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(GRUClassifier, self).__init__()\n",
    "        self.gru = nn.GRU(input_size, hidden_size)\n",
    "        self.h2o = nn.Linear(hidden_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, input_sequence):\n",
    "        # apply GRU to full input sequence, and retain final hidden state\n",
    "        _, hidden = self.gru(input_sequence)\n",
    "        # couple final hidden state to multiclass classifier, i.e., softmax output\n",
    "        output = self.h2o(hidden.view(1, -1)) \n",
    "        output = self.sigmoid(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "8cf42d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 1 # integer encoding\n",
    "hidden_size = 32 \n",
    "output_size = 100 # 100 prolific authors\n",
    "learning_rate = 0.005\n",
    "n_iters = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "bb2265d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, test_loader, optimizer, n_epochs=2):\n",
    "    \"\"\"\n",
    "    Generic training loop for supervised multiclass learning\n",
    "    \"\"\"\n",
    "    LOG_INTERVAL = 250\n",
    "    running_loss, running_accuracy = list(), list()\n",
    "    start_time = time.time()\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    counter = 0 # for debugging\n",
    "\n",
    "    for epoch in range(n_epochs):  # Loop over training dataset `n_epochs` times\n",
    "\n",
    "        epoch_loss = 0.\n",
    "\n",
    "        for i, data in enumerate(train_loader):  # Loop over elements in training set\n",
    "\n",
    "            x, y = data\n",
    "            \n",
    "            x = torch.squeeze(x)\n",
    "            x = torch.unsqueeze(x, dim=1)\n",
    "            x = torch.unsqueeze(x, dim=2)\n",
    "#             if counter < 8 :\n",
    "#                 print(type(x))\n",
    "#                 print(x.shape)\n",
    "#                 counter += 1\n",
    "            results = model(x)\n",
    "\n",
    "#             predictions = torch.argmax(logits, dim=1)\n",
    "            train_acc = 0 # torch.mean(torch.eq(predictions, labels).float()).item()\n",
    "\n",
    "            loss = criterion(input=results, target=y)\n",
    "\n",
    "            loss.backward()               # Backward pass (compute parameter gradients)\n",
    "            optimizer.step()              # Update weight parameter using SGD\n",
    "            optimizer.zero_grad()         # Reset gradients to zero for next iteration\n",
    "\n",
    "\n",
    "            # ============================================================================\n",
    "            # You can safely ignore the boilerplate code below - just reports metrics over\n",
    "            # training and test sets\n",
    "\n",
    "            running_loss.append(loss.item())\n",
    "            running_accuracy.append(train_acc)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            if i % LOG_INTERVAL == 0:  # Log training stats\n",
    "                deltaT = time.time() - start_time\n",
    "                mean_loss = epoch_loss / (i+1)\n",
    "                print('[TRAIN] Epoch {} [{}/{}]| Mean loss {:.4f} | Train accuracy {:.5f} | Time {:.2f} s'.format(epoch, \n",
    "                    i, len(train_loader), mean_loss, train_acc, deltaT))\n",
    "\n",
    "#         print('Epoch complete! Mean loss: {:.4f}'.format(epoch_loss/len(train_loader)))\n",
    "\n",
    "        test(model, criterion, test_loader)\n",
    "        \n",
    "    return running_loss, running_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "436c96f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, criterion, test_loader):\n",
    "    test_loss = 0.\n",
    "    test_preds, test_labels = list(), list()\n",
    "    for i, data in enumerate(test_loader):\n",
    "        x, y = data\n",
    "\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            ### to get the right shape ### \n",
    "            x = torch.squeeze(x)\n",
    "            x = torch.unsqueeze(x, dim=1)\n",
    "            x = torch.unsqueeze(x, dim=2)\n",
    "            ### to get the right shape ### \n",
    "            \n",
    "            results = model(x)  # Compute scores\n",
    "#             test_loss += criterion(input=results, target=y).item()\n",
    "            predictions = torch.where(results > 0.5, 1, 0)\n",
    "            test_preds.append(predictions)\n",
    "#             test_labels.append(y)\n",
    "\n",
    "    test_preds = torch.cat(test_preds)\n",
    "#     test_labels = torch.cat(test_labels)\n",
    "\n",
    "#     test_accuracy = torch.eq(test_preds, test_labels).float().mean().item()\n",
    "\n",
    "#     print('[TEST] Mean loss {:.4f} | Accuracy {:.4f}'.format(test_loss/len(test_loader), test_accuracy))\n",
    "    \n",
    "    return test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "eed2fe36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 0 [0/5000]| Mean loss 0.7233 | Train accuracy 0.00000 | Time 0.02 s\n",
      "[TRAIN] Epoch 0 [250/5000]| Mean loss 0.6781 | Train accuracy 0.00000 | Time 5.20 s\n",
      "[TRAIN] Epoch 0 [500/5000]| Mean loss 0.6440 | Train accuracy 0.00000 | Time 11.18 s\n",
      "[TRAIN] Epoch 0 [750/5000]| Mean loss 0.6124 | Train accuracy 0.00000 | Time 16.84 s\n",
      "[TRAIN] Epoch 0 [1000/5000]| Mean loss 0.5834 | Train accuracy 0.00000 | Time 22.41 s\n",
      "[TRAIN] Epoch 0 [1250/5000]| Mean loss 0.5563 | Train accuracy 0.00000 | Time 28.06 s\n",
      "[TRAIN] Epoch 0 [1500/5000]| Mean loss 0.5309 | Train accuracy 0.00000 | Time 33.86 s\n",
      "[TRAIN] Epoch 0 [1750/5000]| Mean loss 0.5073 | Train accuracy 0.00000 | Time 39.66 s\n",
      "[TRAIN] Epoch 0 [2000/5000]| Mean loss 0.4855 | Train accuracy 0.00000 | Time 45.20 s\n",
      "[TRAIN] Epoch 0 [2250/5000]| Mean loss 0.4653 | Train accuracy 0.00000 | Time 50.81 s\n",
      "[TRAIN] Epoch 0 [2500/5000]| Mean loss 0.4467 | Train accuracy 0.00000 | Time 56.51 s\n",
      "[TRAIN] Epoch 0 [2750/5000]| Mean loss 0.4294 | Train accuracy 0.00000 | Time 62.18 s\n",
      "[TRAIN] Epoch 0 [3000/5000]| Mean loss 0.4135 | Train accuracy 0.00000 | Time 67.98 s\n",
      "[TRAIN] Epoch 0 [3250/5000]| Mean loss 0.3986 | Train accuracy 0.00000 | Time 73.80 s\n",
      "[TRAIN] Epoch 0 [3500/5000]| Mean loss 0.3850 | Train accuracy 0.00000 | Time 79.62 s\n",
      "[TRAIN] Epoch 0 [3750/5000]| Mean loss 0.3722 | Train accuracy 0.00000 | Time 85.41 s\n",
      "[TRAIN] Epoch 0 [4000/5000]| Mean loss 0.3604 | Train accuracy 0.00000 | Time 91.15 s\n",
      "[TRAIN] Epoch 0 [4250/5000]| Mean loss 0.3494 | Train accuracy 0.00000 | Time 97.14 s\n",
      "[TRAIN] Epoch 0 [4500/5000]| Mean loss 0.3391 | Train accuracy 0.00000 | Time 103.28 s\n",
      "[TRAIN] Epoch 0 [4750/5000]| Mean loss 0.3294 | Train accuracy 0.00000 | Time 109.48 s\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 100])) is deprecated. Please ensure they have the same size.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [439]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m GRUClassifier(input_size , hidden_size, output_size)\n\u001b[1;32m      2\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate)\n\u001b[0;32m----> 3\u001b[0m model_loss, model_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [437]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, test_loader, optimizer, n_epochs)\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[TRAIN] Epoch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m [\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m]| Mean loss \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m | Train accuracy \u001b[39m\u001b[38;5;132;01m{:.5f}\u001b[39;00m\u001b[38;5;124m | Time \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m s\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch, \n\u001b[1;32m     52\u001b[0m                     i, \u001b[38;5;28mlen\u001b[39m(train_loader), mean_loss, train_acc, deltaT))\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m#         print('Epoch complete! Mean loss: {:.4f}'.format(epoch_loss/len(train_loader)))\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m         \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m running_loss, running_accuracy\n",
      "Input \u001b[0;32mIn [438]\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(model, criterion, test_loader)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m### to get the right shape ### \u001b[39;00m\n\u001b[1;32m     15\u001b[0m results \u001b[38;5;241m=\u001b[39m model(x)  \u001b[38;5;66;03m# Compute scores\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m test_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     17\u001b[0m predictions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(results \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     18\u001b[0m test_preds\u001b[38;5;241m.\u001b[39mappend(predictions)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:613\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 613\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/functional.py:3074\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3072\u001b[0m     reduction_enum \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[1;32m   3073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize():\n\u001b[0;32m-> 3074\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3075\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing a target size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) that is different to the input size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) is deprecated. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3076\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure they have the same size.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(target\u001b[38;5;241m.\u001b[39msize(), \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m   3077\u001b[0m     )\n\u001b[1;32m   3079\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3080\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n",
      "\u001b[0;31mValueError\u001b[0m: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 100])) is deprecated. Please ensure they have the same size."
     ]
    }
   ],
   "source": [
    "model = GRUClassifier(input_size , hidden_size, output_size)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "model_loss, model_acc = train(model, train_loader, test_loader, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a61e69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f9f638c",
   "metadata": {},
   "source": [
    "Prepare output format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "d9ec2a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_hot_authors_to_integer(authors):\n",
    "    \"\"\"Convert multi hot authors to integer representation\n",
    "\n",
    "    Parameters\n",
    "    ----------        \n",
    "    authors : \n",
    "        A list of zeors and ones of length 100. [0, 0, 0, .... 1, 0, 0, 0, ... 1, 0, 0, .....]\n",
    "        \n",
    "    -------\n",
    "    Return  \n",
    "        A list of author ids (<100). e.g. [23, 47]\n",
    "        return [-1] for empty multi hot representation\n",
    "    \n",
    "    \"\"\"\n",
    "    author_ids = torch.where(authors == 1)[1]\n",
    "    if len(author_ids) > 0:\n",
    "        return author_ids.tolist()\n",
    "    else:\n",
    "        return [-1]\n",
    "\n",
    "def list_of_integers_to_string_format(integers):\n",
    "    \"\"\"Convert integer author ids to string representation\n",
    "\n",
    "    Parameters\n",
    "    ----------        \n",
    "    list of integers : e.g. [1, 2]\n",
    "        \n",
    "    -------\n",
    "    Return: string of format e.g. \"1 2\"\n",
    "    \n",
    "    \"\"\"\n",
    "    return \" \".join([str(author_id) for author_id in integers])\n",
    "    \n",
    "def multi_hot_to_csv(all_test_predictions, test_ids):\n",
    "    test_integers = [ multi_hot_authors_to_integer(pred) for pred in all_test_predictions]\n",
    "    string_integers = list(map(list_of_integers_to_string_format, test_integers))\n",
    "    \n",
    "    header = [\"ID\", \"Predict\"]\n",
    "    test_ids = [str(test_id) for test_id in test_ids]\n",
    "    results = list(zip(test_ids, string_integers))\n",
    "    output = [header] + results\n",
    "    a = np.asarray(output)\n",
    "    np.savetxt(\"foo.csv\", a, delimiter=\",\", fmt='%s')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "e94d8bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "(tensor([0, 0]), tensor([1, 2]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guess = torch.zeros(1, 100, dtype=torch.float32)\n",
    "guess[0][1] = 1\n",
    "guess[0][2] = 1\n",
    "multi_hot_authors_to_integer(guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "126b2037",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = preds[:5].unsqueeze(dim=1)\n",
    "multi_hot_to_csv(predictions, [1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9daeba",
   "metadata": {},
   "source": [
    "Generate test ouputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "1855933a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds = test(model, criterion, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "93284315",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = preds.unsqueeze(dim=1)\n",
    "multi_hot_to_csv(predictions, test_ids.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872d237b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
